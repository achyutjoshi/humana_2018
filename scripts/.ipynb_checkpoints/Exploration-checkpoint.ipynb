{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "1. Validations of relations between different cells. Like \"Diabetes\" show -> Member has Diab Type 2 or not. And \"Diab_Type\" shows type. So whereever Diabetes == 1, Diab_Type should be == \"Type 2\"!!\n",
    "\n",
    "2. Visualisations and Business related answers!! (Ishika, can you please look aggresively into this?)\n",
    "3. Figure out using - \"con_visit....\" , \"pot_visit....\" ,\"rx_ther....\" (Wide format variables!!) \n",
    "4. Separate out different categories of diseases - respiratory, etc etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from csv\n",
    "base_path = \"/Users/apple/Documents/gatech/humana_analytics/humana_2018/\" # path to humana folder\n",
    "\n",
    "data = pd.read_csv(base_path + \"/data/TAMU_FINAL_DATASET_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 448)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data.describe() \n",
    "data.shape\n",
    "#contains one lakh rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take Aways -\n",
    "\n",
    "1. One Lakh rows\n",
    "2. Check for NAs, because there are - Impute them!\n",
    "3. Age distribution of the population is on the older side - min age is 40, max is 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diab_type                        64.693\n",
       "decile_struggle_med_lang         25.215\n",
       "population_density_centile_us    12.179\n",
       "online_purchaser                 12.179\n",
       "dwelling_type                    12.179\n",
       "education_level                  12.179\n",
       "length_residence                 12.179\n",
       "population_density_centile_st    12.179\n",
       "num_person_household             12.179\n",
       "college                          12.179\n",
       "est_bmi_decile                   12.179\n",
       "online_user                      12.179\n",
       "pct_above_poverty_line           12.179\n",
       "pct_below_poverty_line           12.179\n",
       "home_value                       12.179\n",
       "est_net_worth                    12.179\n",
       "est_income                       12.179\n",
       "index_health_ins_engage          12.179\n",
       "index_health_ins_influence       12.179\n",
       "pcp_assignment                    0.157\n",
       "mco_hlvl_plan_cd                  0.033\n",
       "mco_prod_type_cd                  0.033\n",
       "hospice_ind                       0.032\n",
       "esrd_ind                          0.032\n",
       "lis                               0.030\n",
       "institutional                     0.030\n",
       "dual                              0.030\n",
       "orig_reas_entitle_cd              0.030\n",
       "sex_cd                            0.030\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the dataset a bit to make it more general\n",
    "\n",
    "#standardise column names\n",
    "data.columns = [s.lower() for s in data.columns]\n",
    "\n",
    "# find columns with na values\n",
    "def showmissing(df_train):\n",
    "    return df_train.columns[df_train.isnull().any()].tolist()\n",
    "\n",
    "#missing data percentages\n",
    "(data[showmissing(data)].isnull().sum().sort_values(ascending = False)/100000)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\ndata['recon_rx_risk_score_nbr'].describe() \\ndata['recon_ma_risk_score_nbr'].describe()\\ndata['population_density_centile_st']\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "data['recon_rx_risk_score_nbr'].describe() \n",
    "data['recon_ma_risk_score_nbr'].describe()\n",
    "data['population_density_centile_st']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ami_flag</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_cd</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>55476</td>\n",
       "      <td>1292</td>\n",
       "      <td>56768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>41771</td>\n",
       "      <td>1431</td>\n",
       "      <td>43202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>97247</td>\n",
       "      <td>2723</td>\n",
       "      <td>99970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ami_flag      0     1    All\n",
       "sex_cd                      \n",
       "F         55476  1292  56768\n",
       "M         41771  1431  43202\n",
       "All       97247  2723  99970"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more exploration with respect to target variable\n",
    "\n",
    "# We can see that ami_flag is relatively varied among Males and Females. \n",
    "pd.crosstab(index=data['sex_cd'], columns=data['ami_flag'], margins=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning sex_cd Column\n",
    "\n",
    "# Cleaning sex_cd - there are 0.03% NAs in this column. Lets see how we can impute it - or we can remove those rows.\n",
    "data.sex_cd.unique() #there are no \"U\" as expected according to data dictionary. Assuming NAs to be Us\n",
    "data.sex_cd.isnull().sum()  # 30 values. \n",
    "\n",
    "#Interestingly all sex_cd = NAs are people with age=40\n",
    "data[data[\"sex_cd\"].isnull()]['age']\n",
    "\n",
    "buffer = data[data[\"sex_cd\"].isnull()]\n",
    "\n",
    "#We can see that we cannot totally remove the rows believing it to be a data problem because only 10 of the columns are totally NA. \n",
    "(buffer[showmissing(buffer)].isnull().sum().sort_values(ascending = False)/30)*100\n",
    "\n",
    "# For now lets change all the sex_cd = NA with \"U\"\n",
    "\n",
    "data[\"sex_cd\"].fillna(\"U\", inplace = True)\n",
    "data.sex_cd.unique() # F- Female, M- Male, U - Unknown\n",
    "\n",
    "# encoding it\n",
    "sex_dummies = pd.get_dummies(data[\"sex_cd\"])\n",
    "data = data.join(sex_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handling all the NAs value in the dataset. \n",
    "\n",
    "#Step1: Understand why the data has NA. Can it mean something while keeping the domain in mind\n",
    "#Step2: Action to take - remove the rows or impute?\n",
    "#Step3: Return a dataset with no NAs\n",
    "\n",
    "col_with_nas = showmissing(data)\n",
    "\n",
    "# mco_hlvl_plan_cd and mco_hlvl_type_cd\n",
    "data.mco_hlvl_plan_cd.unique()  # ['MAPD', 'MA', nan]\n",
    "data.mco_prod_type_cd.unique()  # ['LPPO', 'PFFS', 'HMO', 'RPPO', nan]\n",
    "\n",
    "#both are NAs for the same person\n",
    "data[data[\"mco_hlvl_plan_cd\"].isnull()]['id'] == data[data[\"mco_prod_type_cd\"].isnull()]['id'] \n",
    "\n",
    "# Decision - Both of these variables are intutively less likely to determine whether a patient will get AMI. \n",
    "# So let the NAs be. \n",
    "\n",
    "data[data[\"est_income\"].isnull()]\n",
    "data.pcp_assignment.unique()\n",
    "\n",
    "#diab_type : Hypothesis - this is NULL whenever diabetes == 0 \n",
    "sum(data[data['diab_type'].isnull()]['id'] == data[data['diabetes'] == 0]['id']) == sum(data['diabetes'] == 0)\n",
    "data[\"diab_type\"].fillna(\"NO\", inplace = True)\n",
    "\n",
    "#esrd_ind \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_cols = [\"id\",\"sex_cd\",\"age\",\"population_density_centile_us\" , \"online_purchaser\", \"dwelling_type\",\"education_level\",\"length_residence\",\"population_density_centile_st\",\"num_person_household\",\"college\",\"est_bmi_decile\",\"online_user\",\"pct_above_poverty_line\",\"pct_below_poverty_line\",\"home_value\",\"est_net_worth\",\"est_income\",\"index_health_ins_engage\", \"index_health_ins_influence\"]   \n",
    "\n",
    "#df_col = data[trial_cols]\n",
    "#df_col[df_col[\"population_density_centile_st\"].isnull()] \n",
    "\n",
    "#sorted(col_with_nas)\n",
    "# Remarks - All the NAs for these columns occur for the same people. This has to be a data collection error! \n",
    "# 12179 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lis</th>\n",
       "      <th>institutional</th>\n",
       "      <th>dual</th>\n",
       "      <th>orig_reas_entitle_cd</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5041</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6050</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6574</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15597</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16041</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16158</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17056</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17057</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18352</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18353</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23929</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23930</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32217</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32235</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33261</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36664</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36665</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39038</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41925</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66297</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67753</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76123</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78004</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81695</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81696</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83116</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83117</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85574</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85575</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90951</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93437</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94022</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94587</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94588</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95569</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95759</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97679</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97680</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98121</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lis institutional dual  orig_reas_entitle_cd     id  age sex_cd\n",
       "5040   NaN           NaN  NaN                   NaN   5041   40      U\n",
       "6049   NaN           NaN  NaN                   NaN   6050   40      U\n",
       "6573   NaN           NaN  NaN                   NaN   6574   40      U\n",
       "15596  NaN           NaN  NaN                   NaN  15597   40      U\n",
       "16040  NaN           NaN  NaN                   NaN  16041   40      U\n",
       "16157  NaN           NaN  NaN                   NaN  16158   40      U\n",
       "17056  NaN           NaN  NaN                   NaN  17057   40      U\n",
       "18352  NaN           NaN  NaN                   NaN  18353   40      U\n",
       "23929  NaN           NaN  NaN                   NaN  23930   40      U\n",
       "32216  NaN           NaN  NaN                   NaN  32217   40      U\n",
       "32234  NaN           NaN  NaN                   NaN  32235   40      U\n",
       "33260  NaN           NaN  NaN                   NaN  33261   40      U\n",
       "36664  NaN           NaN  NaN                   NaN  36665   40      U\n",
       "39037  NaN           NaN  NaN                   NaN  39038   40      U\n",
       "41924  NaN           NaN  NaN                   NaN  41925   40      U\n",
       "66296  NaN           NaN  NaN                   NaN  66297   40      U\n",
       "67752  NaN           NaN  NaN                   NaN  67753   40      U\n",
       "76122  NaN           NaN  NaN                   NaN  76123   40      U\n",
       "78003  NaN           NaN  NaN                   NaN  78004   40      U\n",
       "81695  NaN           NaN  NaN                   NaN  81696   40      U\n",
       "83116  NaN           NaN  NaN                   NaN  83117   40      U\n",
       "85574  NaN           NaN  NaN                   NaN  85575   40      U\n",
       "90950  NaN           NaN  NaN                   NaN  90951   40      U\n",
       "93436  NaN           NaN  NaN                   NaN  93437   40      U\n",
       "94021  NaN           NaN  NaN                   NaN  94022   40      U\n",
       "94587  NaN           NaN  NaN                   NaN  94588   40      U\n",
       "95568  NaN           NaN  NaN                   NaN  95569   40      U\n",
       "95758  NaN           NaN  NaN                   NaN  95759   40      U\n",
       "97679  NaN           NaN  NaN                   NaN  97680   40      U\n",
       "98120  NaN           NaN  NaN                   NaN  98121   40      U"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_cols1 = [\"lis\",\"institutional\",\"dual\",\"orig_reas_entitle_cd\",\"id\",\"age\",\"sex_cd\"]\n",
    "df_col1 = data[trial_cols1]\n",
    "df_col1[df_col1[\"lis\"].isnull()]\n",
    "\n",
    "#These are the same set of people who had their \"sex_cd\" as NA. Data source must be the same as sex_cd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mco_hlvl_plan_cd</th>\n",
       "      <th>mco_prod_type_cd</th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex_cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5041</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6050</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6574</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15597</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16040</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16041</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16157</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16158</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17056</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17057</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18352</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18353</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19348</td>\n",
       "      <td>84</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23929</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23930</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32217</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32235</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33261</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36664</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36665</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39038</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41925</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55302</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55303</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66296</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66297</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67753</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76123</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78004</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78200</td>\n",
       "      <td>59</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81695</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81696</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83116</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83117</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85574</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85575</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90951</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93437</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94022</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94587</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94588</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95569</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95759</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97679</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97680</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98121</td>\n",
       "      <td>40</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mco_hlvl_plan_cd mco_prod_type_cd     id  age sex_cd\n",
       "5040               NaN              NaN   5041   40      U\n",
       "6049               NaN              NaN   6050   40      U\n",
       "6573               NaN              NaN   6574   40      U\n",
       "15596              NaN              NaN  15597   40      U\n",
       "16040              NaN              NaN  16041   40      U\n",
       "16157              NaN              NaN  16158   40      U\n",
       "17056              NaN              NaN  17057   40      U\n",
       "18352              NaN              NaN  18353   40      U\n",
       "19347              NaN              NaN  19348   84      M\n",
       "23929              NaN              NaN  23930   40      U\n",
       "32216              NaN              NaN  32217   40      U\n",
       "32234              NaN              NaN  32235   40      U\n",
       "33260              NaN              NaN  33261   40      U\n",
       "36664              NaN              NaN  36665   40      U\n",
       "39037              NaN              NaN  39038   40      U\n",
       "41924              NaN              NaN  41925   40      U\n",
       "55302              NaN              NaN  55303   68      M\n",
       "66296              NaN              NaN  66297   40      U\n",
       "67752              NaN              NaN  67753   40      U\n",
       "76122              NaN              NaN  76123   40      U\n",
       "78003              NaN              NaN  78004   40      U\n",
       "78199              NaN              NaN  78200   59      M\n",
       "81695              NaN              NaN  81696   40      U\n",
       "83116              NaN              NaN  83117   40      U\n",
       "85574              NaN              NaN  85575   40      U\n",
       "90950              NaN              NaN  90951   40      U\n",
       "93436              NaN              NaN  93437   40      U\n",
       "94021              NaN              NaN  94022   40      U\n",
       "94587              NaN              NaN  94588   40      U\n",
       "95568              NaN              NaN  95569   40      U\n",
       "95758              NaN              NaN  95759   40      U\n",
       "97679              NaN              NaN  97680   40      U\n",
       "98120              NaN              NaN  98121   40      U"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trial_cols2 = [\"hospice_ind\",\"esrd_ind\",\"id\",\"age\",\"sex_cd\"]\n",
    "trial_cols2 = [\"mco_hlvl_plan_cd\",\"mco_prod_type_cd\",\"id\",\"age\",\"sex_cd\"]\n",
    "\n",
    "df_col2 = data[trial_cols2]\n",
    "df_col2[df_col2[\"mco_hlvl_plan_cd\"].isnull()]\n",
    "\n",
    "# For [\"hospice_ind\",\"esrd_ind\"] - Same people like above, except two Males - id = [68995,99088]\n",
    "# For [\"mco_hlvl_plan_cd\",\"mco_prod_type_cd\"] - Same like above except three Males - id [19348,55303,78200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final NAs analysis summary\n",
    "\n",
    "#ids_30 - ids of people who have their sex_cd = U and [\"lis\",\"institutional\",\"dual\",\"orig_reas_entitle_cd\"] = NA\n",
    "ids_30 = list(data[data.sex_cd == \"U\"][\"id\"] )\n",
    "\n",
    "#ids_2 - addition to ids_30, two more person who have [\"hospice_ind\",\"esrd_ind\"] = NA\n",
    "ids_2 = list(data[(data.sex_cd != \"U\") & (data[\"hospice_ind\"].isnull())][\"id\"])\n",
    "\n",
    "#ids_3 - addition to ids_30, three more person who have [\"mco_hlvl_plan_cd\",\"mco_prod_type_cd\"] = NA\n",
    "ids_3 = list(data[(data.sex_cd != \"U\") & (data[\"mco_hlvl_plan_cd\"].isnull())][\"id\"])\n",
    "\n",
    "#pcp_assignment - Waiting to hear back from Humana Team on the meaning behind this\n",
    "\n",
    "# All Variables with 12.79% NAs are demographic variables! Ignore them for now\n",
    "#[\"population_density_centile_us\" , \"online_purchaser\", \"dwelling_type\",\"education_level\",\"length_residence\",\"population_density_centile_st\",\"num_person_household\",\"college\",\"est_bmi_decile\",\"online_user\",\"pct_above_poverty_line\",\"pct_below_poverty_line\",\"home_value\",\"est_net_worth\",\"est_income\",\"index_health_ins_engage\", \"index_health_ins_influence\"]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out variables of interest \n",
    "\n",
    "#personal details\n",
    "numeric_col = [\"age\"]\n",
    "primary_cols = [\"M\",\"F\"]\n",
    "#demographic cols with NAs\n",
    "demographic_cols = [\"population_density_centile_us\" , \"online_purchaser\", \"dwelling_type\",\"education_level\",\"length_residence\",\"population_density_centile_st\",\"num_person_household\",\"college\",\"est_bmi_decile\",\"online_user\",\"pct_above_poverty_line\",\"pct_below_poverty_line\",\"home_value\",\"est_net_worth\",\"est_income\",\"index_health_ins_engage\", \"index_health_ins_influence\"]\n",
    "\n",
    "#health variables\n",
    "adherent_measure = [\"ace_elig\",\"ace_pass\",\"amm\",\"amm_gap\",\"diab_pass\",\"diab_elig\",\"statin_elig\",\"statin_pass\",\"bcs\",\"bcs_gap\",\"col\",\"col_gap\"]\n",
    "\n",
    "disease_1 = [\"ckd\",\"esrd\",\"hyperlipid\",\"hypertension\",\"renal\"]\n",
    "disease_cv = [\"cv_cad\",\"cv_cer\",\"cv_chf\",\"cv_cir\",\"cv_hdz\",\"cv_pvd\",\"cv_sns\"]\n",
    "disease_resp = [\"res_ast\",\"res_alg\",\"res_copd\",\"res_fail\",\"res_inf\"]\n",
    "disease_movement = [\"arth\",\"muscul_bn\",\"muscul_oth\",\"osteo\"]\n",
    "disease_sugar = [\"prediabetes\",\"diab_complications\",\"diabetes\",\"cdc\",\"cdc_eye_gap\" ,\n",
    "                 \"cdc_hbapoor_gap\",\"cdc_hbatest_gap\",\"cdc_nph_gap\"]\n",
    "\n",
    "scores = [\"recon_ma_risk_score_nbr\",\"recon_rx_risk_score_nbr\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99965, 451)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing 32 persons whose some imp health variables are NAs\n",
    "# For now removing it, we can think of how to improve this later\n",
    "\n",
    "remove_ids = ids_30 + ids_2 + ids_3\n",
    "data = data[~data[\"id\"].isin(remove_ids)]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test\n",
    "\n",
    "data.ami_flag = pd.Categorical(data.ami_flag)\n",
    "\n",
    "# converting categorical into categorical\n",
    "data[primary_cols + adherent_measure + disease_1 +disease_cv +disease_resp+disease_movement+disease_sugar] = data[primary_cols + adherent_measure + disease_1 +disease_cv +disease_resp+disease_movement+disease_sugar].apply( pd.Categorical,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target_df = data['ami_flag']\n",
    "\n",
    "#choosing the diseases variables\n",
    "\n",
    "var = primary_cols + adherent_measure + disease_1 +disease_cv +disease_resp+disease_movement+disease_sugar+scores\n",
    "#variable_df = data.drop('ami_flag', axis = 1)\n",
    "variable_df = data[var]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(variable_df, target_df, test_size=0.2) #20% data in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 1.72464703e-02 -1.74633354e+00 -1.96682934e+00  1.30605796e-01\n",
      "  -1.76860498e-01  6.92733751e-02  4.29224526e-03 -3.10598864e-01\n",
      "   2.02341882e-01 -4.35305628e-02 -2.95667820e-01 -1.54724677e-01\n",
      "   2.38514469e-01 -2.05623846e-01  1.98939313e-01  1.28238170e-01\n",
      "   7.19920648e-01 -8.73336016e-02  8.82262781e-02  1.59875573e-03\n",
      "   9.55087253e-01  1.60955157e-01  2.61540869e-01  8.96114020e-02\n",
      "   5.00700260e-02  2.36782527e-03  4.01388119e-01 -1.56559061e-01\n",
      "   4.95331629e-03  2.23827411e-01  1.66550227e-01 -1.16360856e-02\n",
      "  -1.14068898e-01  6.89288169e-02 -1.85755016e-01  1.63711978e-01\n",
      "  -2.15462844e-01  3.61722758e-01  1.11627034e-01 -9.83881922e-03\n",
      "   1.02651423e-01  1.74385758e-01  7.99027067e-02 -1.85362597e-01\n",
      "   8.09955999e-02 -3.51612976e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Trying out linear regression\n",
    "\n",
    "linear_reg = linear_model.LogisticRegression()\n",
    "\n",
    "linear_reg.fit(X_train,y_train)\n",
    "\n",
    "predictions = linear_reg.predict(X_test)\n",
    "\n",
    "print('Coefficients: \\n', linear_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9842755 , 0.0157245 ],\n",
       "       [0.97886803, 0.02113197],\n",
       "       [0.98334403, 0.01665597],\n",
       "       ...,\n",
       "       [0.97506998, 0.02493002],\n",
       "       [0.99138453, 0.00861547],\n",
       "       [0.85560783, 0.14439217]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=y_test, columns=predictions)\n",
    "\n",
    "linear_reg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5,random_state=0)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0467452  0.00771296 0.00522369 0.00216992 0.00364452 0.00503838\n",
      " 0.00160582 0.00274173 0.00282916 0.00325742 0.00622745 0.00559592\n",
      " 0.00230719 0.00486798 0.00122325 0.01344412 0.03186657 0.00304912\n",
      " 0.00318535 0.0112071  0.25194031 0.01954774 0.09995516 0.01813763\n",
      " 0.06216097 0.00885172 0.08534436 0.00235269 0.00175082 0.01618066\n",
      " 0.0321711  0.00290017 0.00344276 0.00275673 0.00123814 0.00142676\n",
      " 0.00361496 0.03803011 0.02062899 0.00309468 0.00378026 0.00412326\n",
      " 0.00269238 0.00097795 0.09899319 0.0499637 ]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98114662, 0.01885338],\n",
       "       [0.98061558, 0.01938442],\n",
       "       [0.98453237, 0.01546763],\n",
       "       ...,\n",
       "       [0.96883401, 0.03116599],\n",
       "       [0.98908328, 0.01091672],\n",
       "       [0.91043696, 0.08956304]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.crosstab(index=y_test, columns=predictions)\n",
    "\n",
    "clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-0abfd23330bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not str"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf1 = svm.SVC(gamma='scale')\n",
    "clf1.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                        category\n",
       "M                          category\n",
       "F                          category\n",
       "ace_elig                   category\n",
       "ace_pass                   category\n",
       "amm                        category\n",
       "amm_gap                    category\n",
       "diab_pass                  category\n",
       "diab_elig                  category\n",
       "statin_elig                category\n",
       "statin_pass                category\n",
       "bcs                        category\n",
       "bcs_gap                    category\n",
       "col                        category\n",
       "col_gap                    category\n",
       "ckd                        category\n",
       "esrd                       category\n",
       "hyperlipid                 category\n",
       "hypertension               category\n",
       "renal                      category\n",
       "cv_cad                     category\n",
       "cv_cer                     category\n",
       "cv_chf                     category\n",
       "cv_cir                     category\n",
       "cv_hdz                     category\n",
       "cv_pvd                     category\n",
       "cv_sns                     category\n",
       "res_ast                    category\n",
       "res_alg                    category\n",
       "res_copd                   category\n",
       "res_fail                   category\n",
       "res_inf                    category\n",
       "arth                       category\n",
       "muscul_bn                  category\n",
       "muscul_oth                 category\n",
       "osteo                      category\n",
       "prediabetes                category\n",
       "diab_complications         category\n",
       "diabetes                   category\n",
       "cdc                        category\n",
       "cdc_eye_gap                category\n",
       "cdc_hbapoor_gap            category\n",
       "cdc_hbatest_gap            category\n",
       "cdc_nph_gap                category\n",
       "recon_ma_risk_score_nbr     float64\n",
       "recon_rx_risk_score_nbr     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
